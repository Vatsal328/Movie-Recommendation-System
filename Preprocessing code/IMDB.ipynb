{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Sample URL template for IMDb movie pages\n",
    "base_url = \"https://www.imdb.com/title/tt{:0>7}\"  # Updated URL template with 7-digit IMDb ID\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Read the DataFrame from the provided CSV file containing IMDb movie data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Vatsal328/Movie-Recommendation-System/main/Dataset/links.csv\")\n",
    "\n",
    "# Create and open the CSV file in append mode to store scraped data\n",
    "with open('scraped_data_imdb_new.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "    # Write the header row if the file is empty\n",
    "    if f.tell() == 0:\n",
    "        f.write('imdbId,Ratings,Popularity,User Reviews,Critic Reviews,Metascore\\n')\n",
    "\n",
    "    # Iterate through each IMDb ID in the DataFrame for scraping data\n",
    "    for imdbId in df['imdbId'][8275:]:\n",
    "        imdbId_str = str(imdbId).zfill(7)  # Ensure IMDb ID is 7 digits\n",
    "        url = base_url.format(imdbId_str)\n",
    "        page = requests.get(url, headers=headers)\n",
    "\n",
    "        if page.status_code != 200:\n",
    "            print(f\"Error fetching data for IMDb ID {imdbId}. Status code: {page.status_code}\")\n",
    "            print(url)\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        ratings = None\n",
    "        popularity = None\n",
    "        user_reviews = None\n",
    "        critic_reviews = None\n",
    "        metascore = None\n",
    "\n",
    "        # Extract ratings from the IMDb page\n",
    "        data_rating = soup.find('span', attrs={'class': 'sc-bde20123-1 cMEQkK'})\n",
    "        if data_rating:\n",
    "            rating = data_rating.text.strip()\n",
    "            ratings = rating\n",
    "\n",
    "        # Extract popularity score from the IMDb page\n",
    "        data_popularity = soup.find('div', {'data-testid': 'hero-rating-bar__popularity__score', 'class': 'sc-5f7fb5b4-1 fTREEx'})\n",
    "        if data_popularity:\n",
    "            popularity_score = data_popularity.text.strip().replace(',', '')  # Remove commas from popularity count\n",
    "            popularity = popularity_score\n",
    "\n",
    "        # Extract user reviews, critic reviews, and metascore from the IMDb page\n",
    "        reviews = soup.findAll('span', {'class': 'score'})\n",
    "        for i in range(len(reviews)):\n",
    "            if reviews[i] == 'User reviews':\n",
    "                user_reviews = reviews[i - 1]\n",
    "            elif reviews[i] == 'Critic reviews':\n",
    "                critic_reviews = reviews[i - 1]\n",
    "            elif reviews[i] == 'Metascore':\n",
    "                metascore = reviews[i - 1]\n",
    "\n",
    "        # Write scraped data to the CSV file\n",
    "        f.write(f'{imdbId},{ratings},{popularity},{user_reviews},{critic_reviews},{metascore}\\n')\n",
    "\n",
    "# Read the updated CSV file into a DataFrame for further analysis or verification\n",
    "scraped_data = pd.read_csv('scraped_data_imdb_new.csv')\n",
    "print(scraped_data.head())\n",
    "\n",
    "# Check the shape of the scraped_data DataFrame\n",
    "print(\"Shape of scraped_data:\", scraped_data.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
